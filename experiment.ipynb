{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import TicTacToeEnv\n",
    "import random\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.model import Sequential\n",
    "\n",
    "env = gym.make('tictactoe-v0')\n",
    "\n",
    "def create_agent_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # each position can be empty, 0 or 1 and there are 9 positions\n",
    "    # we encode each position with two 0/1 values.  empty = 0/0, player1 = 1/0, player2 = 0/1\n",
    "    model.add(layers.Dense(18, activation=\"relu\"))\n",
    "    model.add(layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(layers.Dense(9))\n",
    "    \n",
    "    optimizer =  optimizers.Adam(learning_rate=0.01)\n",
    "    loss = losses.MeanSquaredError()\n",
    "    model.compile(optimizer, loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.env = env\n",
    "        self.use_randomness = False\n",
    "        self.random_rate = 0.2\n",
    "        \n",
    "    def set_random_rate(self, rate):\n",
    "        self.random_rate = rate\n",
    "        \n",
    "    def get_action(self, env):\n",
    "        if self.use_randomness:\n",
    "            return random.randint(0,8)\n",
    "        else:\n",
    "            best_action = self._get_best_action()\n",
    "            return best_action\n",
    "    \n",
    "    def _get_best_action(self):\n",
    "        best_action = np.argmax(self.model.predict(np.array([env._one_hot_board()])))\n",
    "        return best_action\n",
    "        \n",
    "    def _get_random_action(self):\n",
    "        # truly random, so could yield invalid moves\n",
    "        return random.randint(0, 8)\n",
    "    \n",
    "    def set_use_randomness(self, value):\n",
    "        self.use_randomness = value\n",
    "    \n",
    "    #TODO: get random *valid* action and get best *valid* action (to avoid invalid moves when not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_experience(env, agent):\n",
    "    # plays a game until it's done, recording all steps into tuples (state, action, reward, next_state, done)\n",
    "    env.reset()\n",
    "    done = False\n",
    "    experience = []\n",
    "    while not done:\n",
    "        action = agent.get_action(env)\n",
    "        state = env._one_hot_board()\n",
    "        step_result = env.step(action)\n",
    "        (next_state, reward, done, info) = step_result\n",
    "        \n",
    "        experience.append((state, action, reward, next_state, done))\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_agent_model()\n",
    "agent = Agent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "round 0, game duration 5\n",
      "1/1 [==============================] - 0s 745us/step - loss: 2.9503\n",
      "round 100, game duration 5\n",
      "1/1 [==============================] - 0s 739us/step - loss: 2.3304\n",
      "round 200, game duration 3\n",
      "1/1 [==============================] - 0s 728us/step - loss: 2.1806\n",
      "round 300, game duration 3\n",
      "1/1 [==============================] - 0s 683us/step - loss: 1.5559\n",
      "round 400, game duration 5\n",
      "1/1 [==============================] - 0s 678us/step - loss: 2.0525\n",
      "round 500, game duration 4\n",
      "1/1 [==============================] - 0s 755us/step - loss: 0.5861\n",
      "round 600, game duration 5\n",
      "1/1 [==============================] - 0s 754us/step - loss: 0.1100\n",
      "round 700, game duration 2\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.5485\n",
      "round 800, game duration 4\n",
      "1/1 [==============================] - 0s 668us/step - loss: 1.4242\n",
      "round 900, game duration 3\n",
      "1/1 [==============================] - 0s 703us/step - loss: 0.4991\n",
      "round 1000, game duration 4\n",
      "1/1 [==============================] - 0s 970us/step - loss: 0.8602\n",
      "round 1100, game duration 4\n",
      "1/1 [==============================] - 0s 675us/step - loss: 0.8366\n",
      "round 1200, game duration 5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2092\n",
      "round 1300, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3183\n",
      "round 1400, game duration 7\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9867\n",
      "round 1500, game duration 5\n",
      "1/1 [==============================] - 0s 828us/step - loss: 1.0038\n",
      "round 1600, game duration 3\n",
      "1/1 [==============================] - 0s 674us/step - loss: 0.4252\n",
      "round 1700, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9420\n",
      "round 1800, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7095\n",
      "round 1900, game duration 7\n",
      "1/1 [==============================] - 0s 757us/step - loss: 4.3728\n",
      "round 2000, game duration 6\n",
      "1/1 [==============================] - 0s 618us/step - loss: 0.8769\n",
      "round 2100, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9783\n",
      "round 2200, game duration 2\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2139\n",
      "round 2300, game duration 6\n",
      "1/1 [==============================] - 0s 681us/step - loss: 0.9095\n",
      "round 2400, game duration 6\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8865\n",
      "round 2500, game duration 6\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1831\n",
      "round 2600, game duration 3\n",
      "1/1 [==============================] - 0s 687us/step - loss: 0.6400\n",
      "round 2700, game duration 6\n",
      "1/1 [==============================] - 0s 689us/step - loss: 7.8618\n",
      "round 2800, game duration 5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3509\n",
      "round 2900, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7376\n",
      "round 3000, game duration 6\n",
      "1/1 [==============================] - 0s 836us/step - loss: 1.5695\n",
      "round 3100, game duration 4\n",
      "1/1 [==============================] - 0s 717us/step - loss: 3.9206\n",
      "round 3200, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5362\n",
      "round 3300, game duration 5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6873\n",
      "round 3400, game duration 5\n",
      "1/1 [==============================] - 0s 675us/step - loss: 1.3790\n",
      "round 3500, game duration 7\n",
      "1/1 [==============================] - 0s 724us/step - loss: 0.7670\n",
      "round 3600, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7657\n",
      "round 3700, game duration 4\n",
      "1/1 [==============================] - 0s 821us/step - loss: 1.0219\n",
      "round 3800, game duration 4\n",
      "1/1 [==============================] - 0s 879us/step - loss: 0.5499\n",
      "round 3900, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5187\n",
      "round 4000, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4029\n",
      "round 4100, game duration 5\n",
      "1/1 [==============================] - 0s 672us/step - loss: 0.3735\n",
      "round 4200, game duration 5\n",
      "1/1 [==============================] - 0s 744us/step - loss: 40786.2500\n",
      "round 4300, game duration 6\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 148.1724\n",
      "round 4400, game duration 2\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1859.3906\n",
      "round 4500, game duration 6\n",
      "1/1 [==============================] - 0s 665us/step - loss: 2250.2285\n",
      "round 4600, game duration 6\n",
      "1/1 [==============================] - 0s 665us/step - loss: 5246.9004\n",
      "round 4700, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1224.6561\n",
      "round 4800, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2492.5676\n",
      "round 4900, game duration 3\n",
      "1/1 [==============================] - 0s 855us/step - loss: 2232.6238\n",
      "round 5000, game duration 5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2147.6091\n",
      "round 5100, game duration 5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2484.3125\n",
      "round 5200, game duration 5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1563.1260\n",
      "round 5300, game duration 3\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 86.1410\n",
      "round 5400, game duration 4\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 356.0193\n",
      "round 5500, game duration 5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1253.0068\n",
      "round 5600, game duration 7\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 508.4166\n",
      "round 5700, game duration 4\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.8773\n",
      "round 5800, game duration 4\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 425.2238\n",
      "round 5900, game duration 4\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 432.9551\n",
      "round 6000, game duration 5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1038.8239\n",
      "round 6100, game duration 6\n",
      "1/1 [==============================] - 0s 984us/step - loss: 1059.6873\n",
      "round 6200, game duration 2\n",
      "1/1 [==============================] - 0s 965us/step - loss: 1385.0869\n",
      "round 6300, game duration 7\n",
      "1/1 [==============================] - 0s 920us/step - loss: 725.2462\n",
      "round 6400, game duration 4\n",
      "1/1 [==============================] - 0s 985us/step - loss: 1090.9877\n",
      "round 6500, game duration 5\n",
      "1/1 [==============================] - 0s 880us/step - loss: 1133.2775\n",
      "round 6600, game duration 5\n",
      "1/1 [==============================] - 0s 898us/step - loss: 36.6844\n",
      "round 6700, game duration 2\n",
      "1/1 [==============================] - 0s 938us/step - loss: 72.3188\n",
      "round 6800, game duration 4\n",
      "1/1 [==============================] - 0s 908us/step - loss: 251.0304\n",
      "round 6900, game duration 4\n",
      "1/1 [==============================] - 0s 939us/step - loss: 1829.0361\n",
      "round 7000, game duration 4\n",
      "1/1 [==============================] - 0s 859us/step - loss: 714.2454\n",
      "round 7100, game duration 2\n",
      "1/1 [==============================] - 0s 880us/step - loss: 101.6847\n",
      "round 7200, game duration 4\n",
      "1/1 [==============================] - 0s 941us/step - loss: 659.3707\n",
      "round 7300, game duration 5\n",
      "1/1 [==============================] - 0s 868us/step - loss: 354.4003\n",
      "round 7400, game duration 6\n",
      "1/1 [==============================] - 0s 843us/step - loss: 23.9730\n",
      "round 7500, game duration 3\n",
      "1/1 [==============================] - 0s 879us/step - loss: 308.9807\n",
      "round 7600, game duration 8\n",
      "1/1 [==============================] - 0s 870us/step - loss: 999.4569\n",
      "round 7700, game duration 5\n",
      "1/1 [==============================] - 0s 873us/step - loss: 776.1857\n",
      "round 7800, game duration 3\n",
      "1/1 [==============================] - 0s 878us/step - loss: 2.3178\n",
      "round 7900, game duration 2\n",
      "1/1 [==============================] - 0s 877us/step - loss: 157.8242\n",
      "round 8000, game duration 5\n",
      "1/1 [==============================] - 0s 859us/step - loss: 584.1582\n",
      "round 8100, game duration 5\n",
      "1/1 [==============================] - 0s 931us/step - loss: 250.6547\n",
      "round 8200, game duration 4\n",
      "1/1 [==============================] - 0s 965us/step - loss: 19.5304\n",
      "round 8300, game duration 5\n",
      "1/1 [==============================] - 0s 905us/step - loss: 483.4350\n",
      "round 8400, game duration 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 870us/step - loss: 344.4851\n",
      "round 8500, game duration 5\n",
      "1/1 [==============================] - 0s 922us/step - loss: 106.9395\n",
      "round 8600, game duration 4\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4045\n",
      "round 8700, game duration 4\n",
      "1/1 [==============================] - 0s 861us/step - loss: 75.7940\n",
      "round 8800, game duration 3\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 233.9208\n",
      "round 8900, game duration 5\n",
      "1/1 [==============================] - 0s 863us/step - loss: 56.2459\n",
      "round 9000, game duration 4\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 78.6765\n",
      "round 9100, game duration 4\n",
      "1/1 [==============================] - 0s 865us/step - loss: 4.9784\n",
      "round 9200, game duration 2\n",
      "1/1 [==============================] - 0s 895us/step - loss: 40.0656\n",
      "round 9300, game duration 6\n",
      "1/1 [==============================] - 0s 902us/step - loss: 205.2079\n",
      "round 9400, game duration 7\n",
      "1/1 [==============================] - 0s 912us/step - loss: 64.3700\n",
      "round 9500, game duration 5\n",
      "1/1 [==============================] - 0s 929us/step - loss: 144.3700\n",
      "round 9600, game duration 3\n",
      "1/1 [==============================] - 0s 967us/step - loss: 3.2600\n",
      "round 9700, game duration 2\n",
      "1/1 [==============================] - 0s 887us/step - loss: 7.8350\n",
      "round 9800, game duration 5\n",
      "1/1 [==============================] - 0s 939us/step - loss: 123.1166\n",
      "round 9900, game duration 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  work in progress\n",
    "\n",
    "def train_model(experiences, model, verbose=False):\n",
    "    start_states = np.array([e[0] for e in experiences])\n",
    "    actions = np.array([e[1] for e in experiences])\n",
    "    rewards = np.array([e[2] for e in experiences])\n",
    "    next_states = np.array([e[3] for e in experiences])\n",
    "    predictions  = model.predict(start_states)\n",
    "    next_predictions = model.predict(next_states)\n",
    "    \n",
    "    gamma = 0.95\n",
    "    for prediction,action,reward,next_prediction in zip(predictions, actions, rewards, next_predictions):\n",
    "        prediction[action] = reward + gamma * np.max(next_prediction)\n",
    "    \n",
    "    model.fit(x=start_states, y=predictions, epochs=1, verbose=verbose)\n",
    "    \n",
    "def train_game_per_game(num_games, env, agent):\n",
    "    for i in range(num_games):\n",
    "        if i%100 == 0:\n",
    "            experience = record_experience(env, agent)\n",
    "            train_model(experience, model, verbose=True)\n",
    "            print(\"round %d, game duration %d\"%(i, len(experience)))\n",
    "        else:\n",
    "            experience = record_experience(env, agent)\n",
    "            train_model(experience, model)\n",
    "            \n",
    "def train_batch_experiences(num_actions, env, agent, verbose=False):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    experiences = []\n",
    "    for i in range(num_actions):\n",
    "        action = agent.get_action(env)\n",
    "        state = env._one_hot_board()\n",
    "        \n",
    "        step_result = env.step(action)\n",
    "        (next_state, reward, done, info) = step_result\n",
    "        \n",
    "        experiences.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        if done:\n",
    "            env.reset()\n",
    "      \n",
    "    print(\"training with %d experiences\"%(len(experiences)))\n",
    "    train_model(experiences, model, verbose)\n",
    "\n",
    "agent.set_use_randomness(True)\n",
    "train_game_per_game(10000, env, agent)\n",
    "#for epoch in range(5000):\n",
    "#    print(\"epoch\", epoch)\n",
    "#    train_batch_experiences(100, env, agent, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env, agent):\n",
    "    done = False\n",
    "    env.reset()\n",
    "    env.render()\n",
    "    while not done:\n",
    "        action = agent.get_action(env)\n",
    "        print(\"prediction\", model.predict(np.array([env._one_hot_board()])))\n",
    "        print(\"action:\", action)\n",
    "        obs,reward,done,info = env.step(action)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "prediction [[104.399086 106.468605 107.04008  100.85167  117.147606 105.31688\n",
      "   98.74773  113.27484   99.71636 ]]\n",
      "action: 4\n",
      "0 0 0\n",
      "0 1 0\n",
      "0 0 0\n",
      "prediction [[157.175   160.42621 156.68333 158.6314  169.54083 166.26317 158.28264\n",
      "  164.12338 156.46956]]\n",
      "action: 4\n",
      "0 0 0\n",
      "0 1 0\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "agent.set_use_randomness(False)\n",
    "play_game(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "prediction [[104.399086 106.468605 107.04008  100.85167  117.147606 105.31688\n",
      "   98.74773  113.27484   99.71636 ]]\n",
      "action: 4\n",
      "0 0 0\n",
      "0 1 0\n",
      "0 0 0\n",
      "prediction [[157.175   160.42621 156.68333 158.6314  169.54083 166.26317 158.28264\n",
      "  164.12338 156.46956]]\n",
      "action: 4\n",
      "0 0 0\n",
      "0 1 0\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "play_game(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
